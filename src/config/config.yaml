defaults:
  - dataset: numbers
common:
  seed: 1337
model:
  path: # Path to saved model to continue training
  channels: [256, 256, 512, 512, 512]  # C in paper
  kernels: [33, 39, 51, 63, 75]        # K in paper
  repeats: [3, 3, 3, 3, 3]             # R in paper
  block_repeats: [1, 1, 1, 1, 1]       # S in paper
preprocessing:
  f_min: 0
  f_max: 8000
  n_fft: 512
  n_mels: 64
training:
  device: cuda
  n_epochs: 300
  lr: 1e-3
  num_workers: 6
  batch_size: 50
waveform_transforms:
  - _target_: core.transforms.Resample
    orig_freq: ${dataset.original_sample_rate}
    new_freq: ${dataset.sample_rate}
  - _target_: core.transforms.ToNumpy
  - _target_: core.transforms.Squeeze
#  - _target_: audiomentations.AddGaussianNoise
#    min_amplitude: 0.001
#    max_amplitude: 0.015
#    p: 0.5
#  - _target_: audiomentations.TimeStretch
#    min_rate: 0.8
#    max_rate: 1.25
#    p: 0.5
#  - _target_: audiomentations.PitchShift
#    min_semitones: -4
#    max_semitones: 4
#    p: 0.5
  - _target_: core.transforms.MelSpectrogram
    sample_rate: ${dataset.sample_rate}
    f_min: ${preprocessing.f_min}
    f_max: ${preprocessing.f_max}
    n_fft: ${preprocessing.n_fft}
    n_mels: ${preprocessing.n_mels}
  - _target_: core.transforms.LogTransform
bpe:
  vocab_size: 24
  train_data_path: "bpe_data.txt"
  model_path: "bpe-${dataset.name}-${bpe.vocab_size}.model"
wandb:
  project: "QuartzNet-Tamerlan-Tabolov"
  log_interval: 10
